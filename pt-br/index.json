[{"content":"Em todas as minhas experiências profissionais até agora eu vi várias pessoas/times ignorando o significado por trás de um Pull Request (PR), tratando ele só como um tipo de burocracia para colocar o código em produção.\nAlgumas vezes escutei pessoas falando uma para outra: \u0026ldquo;Vou abrir um PR aqui, aceita ai que está tudo certo\u0026rdquo;. No final esse PR foi realmente aceito sem nenhum tipo de revisão e acabou quebrando todo o sistema, posso dizer que o revisor é tão culpado quanto o revisado porque nesse caso o revisor foi negligente!\nNós não conseguimos automatizar tudo, as pessoas pensam que por terem testes automatizados não precisam fazer mais nada para garantir a qualidade do código.\nEstá dentro de testes automatizados:\n Testes unitários, testes de integração e etc. Testes estáticos (linters) Testes de Tipagem Estática (se você estiver usando uma linguagem com tipagem estática opcional, como Python)  Nos próximos tópicos, vou tentar explicar meu ponto de vista sobre código e sua qualidade no mundo profissional\nO que é o código?  Todo projeto/codebase é um ativo da empresa.\n O código que nós escrevemos não é nosso, ele pertence à empresa. Nós só estamos momentaneamente responsáveis por ele, talvez daqui algumas semanas o projeto vá para outro time, e outro projeto pode vir para nosso time também!\nPelo fato de que os projetos podem ser movimentados entre os times, é nosso dever manter a qualidade do código que escrevemos, nós precisamos nos preocupar não porque alguém quer mas porque devemos, é uma tarefa de todos que escrevem/produzem código.\nQualidade  Manter a qualidade é ter empatia com quem mantinha, mantém e irá manter o código.\n Muitas pessoas acham que testes automatizados são suficiente para garantir a qualidade mas a equação deveria ser algo como:\n qualidade = testes automatizados + legibilidade + manutenibilidade + uma boa arquitetura\n Por que o processo de revisão existe no Pull Request se eu posso mergear o código depois que os testes rodaram com sucesso?\nPorque nós não podemos garantir a legibilidate, manutenibilidade e a qualidade da arquitetura. As pessoas acham que rodando um linter e tendo 100% de cobertura de código é o suficiente, mas não é.\nLembre-se, cobertura de código não significa qualidade de teste!\nComo um time, nós somos reponsáveis pelo código da branch main. Quando alguém cria outras branches para implementar uma nova feature ou arrumar algum bug, quem criou a branch e o revisor são resposáveis por garantir a qualidade do código que será mergeado na branch main.\nAlgumas pessoas falam que o código é só o meio para criar/chegar no produto, mas se esse código não tem qualidade e definição, o que será do produto?\nProvavelmente um produto que ninguém vai querer dar manutenção porque será muito difícil de entender como ele funciona.\nPull Request Um Pull Request é um pedido para adicionar/modificar um ativo da empresa, é algo que já pode estar em produção, então, nós precisamos garantir uma alta qualidade porque nossos consumidores/usuários serão afetados diretamente.\nO Pull Request é onde nós podemos validar todo aspecto da qualidade do código que irá ser mergerado na branch main, tentando reduzir qualquer possível erro no código!\nUma das partes mais legais sobre Pull Requests é que todos aprendemos alguma coisa, tanto o revisor quanto o revisado.\n Agradecimentos especiais para as pessoas que revisaram esse post:\n Nikita Sobolevn Gustavo Millen Bruno Delfino  ","permalink":"https://thepabloaguilar.dev/pt-br/nao-e-so-um-pull-request/","summary":"Em todas as minhas experiências profissionais até agora eu vi várias pessoas/times ignorando o significado por trás de um Pull Request (PR), tratando ele só como um tipo de burocracia para colocar o código em produção.\nAlgumas vezes escutei pessoas falando uma para outra: \u0026ldquo;Vou abrir um PR aqui, aceita ai que está tudo certo\u0026rdquo;. No final esse PR foi realmente aceito sem nenhum tipo de revisão e acabou quebrando todo o sistema, posso dizer que o revisor é tão culpado quanto o revisado porque nesse caso o revisor foi negligente!","title":"Não é só um Pull Request"},{"content":"Contexto Há alguns meses atrás comecei a contribuir em biblioteca Open Source para python, returns, ela têm vários recursos e contêineres legais para nos ajudar de diferentes maneiras. Não irei me aprofundar neles nesse post, mas você pode acessar a documentação para saber mais sobre!\nNesse post irei falar sobre o porquê nós escolhemos a técnica de monkey patching para implementar uma de nossas features onde o objetivo era melhorar a rastreabilidade de falhas para os contêineres Result.\nUma breve explicação sobre o que é o Result, basicamente, seu código pode ter dois caminhos:\n Sucesso, seu código executou normalmente sem nenhum erro Falha, seu código falhou por alguma razão, por exemplo, uma quebra de regra de negócio ou uma exceção foi lançada  O contêiner abstrai esses possíveis caminhos para nós, veja o exemplo abaixo:\nfrom returns.result import Failure, Result, Success def eh_par(numero: int) -\u0026gt; Result[int, int]: if arg % 2 == 0: return Success(numero) return Failure(numero) assert eh_par(2) == Success(2) assert eh_par(1) == Failure(1) Usar o Result pode ser uma boa ideia porque você não precisa mais lidar com exceções (négocio, sistema) lançadas e sair colocando try...except em todo lugar do seu código, você precisa apenas retornar um contêiner Failure.\nRastreabilidade de Falhas: explicação da feature Failure é bom, mas exceções normais nos dão algo importante: onde elas foram lançadas.\nInspirado na feature de rastreamento de falhas do dry-rb, que é uma coleção de bibliotecas para Ruby, nós começamos as discussões para oferecer essa opção para os usuários da returns. Uma coisa muito importante foi considerada para fazer a implementação, que os usuários que não fossem utilizar a feature não poderiam ter a performance dos seus sistemas/aplicações afetada!\nA forma simples, fácil e única (eu acho) para implementar a feature é pegarmos a pilha de chamadas e fazer algumas manipulações com ela. Em Python é bem simples fazermos isso, porém é uma operação bem custosa que pode afetar a performance se for feita muitas vezes. Abaixo você consegue ver as métricas extraídas sobre o consumo de memória quando criamos um contêiner Failure pegando e não pegando a pilha de chamadas, respectivamente:\nComo nós podemos implementar a feature de rastreamento? Nós já sabemos que o rastreamento deve ser opcional, dado que usuários que não irão utiliza-lo não podem ser afetados, e como vimos nas imagems acima, quando ativamos o rastreamento (pegando a pilha de chamadas) tivemos um consumo grande de memória comparada sem o rastreamento!\nPara tornar o rastremento opcional tinhamos duas opções:\n Usar uma variável de ambiente Usar monkey patching  Pelo título desse post você já deve saber que escolhemos a segunda opção.\nPor que monkey patching?\nMonkey Patching é a abordagem mais sofisticada e elegante do que utilizar uma variável de ambiente, nós podemos separar de maneira correta a código da feature de rastreamento da classe que queremos que seja rastreável e não dependemos de nenhum recurso externo. Usando uma variável de ambiente acabaríamos com algo similar ao exemplo abaixo em nossas classes, nós podemos desacoplar a estrutura do if da classe porém em algum outro lugar do nosso código esse if estaria lá:\nimport os class Exemplo: def __init__(self) -\u0026gt; None: if os.getenv(\u0026#39;RETURNS_TRACE\u0026#39;): self._tracking = [] Monkey patching é um amigo conhecido dos programadores Python, nós usamos muito enquanto escrevemos testes para fazermos mocks de tudo que queremos (requests para API, interações com o banco de dados e etc.), porém não é muito utilizado em códigos de \u0026ldquo;produção\u0026rdquo; porque temos algumas desvantagens, como por exemplo, ele não é Thread Safe e pode criar vários bugs dado que ele afeta o código base inteiro em runtime. Mas nós entendemos que a feature de rastreamento é para propósitos de desenvolvimento, nós não nos importamos com o problema de thread safety e sabemos exatamente onde iremos usar o monkey patching!\n Podemos ter um monkey patching que seja thread safe em Python?\nSim, podemos. Mas isso é um assunto para outro artigo.\n Depois de algumas discussões, nós finalmente entregamos nossa feature de rastreamento de falhas, e agora nossos usuários podem ativar explicitamente em seus códigos o rastreamento para os contêineres Result.\nfrom returns.result import Failure, Result from returns.primitives.tracing import collect_traces @collect_traces def retorna_falha(argumento: str) -\u0026gt; Result[str, str]: return Failure(argumento) failure = retorna_falha(\u0026#39;example\u0026#39;) for trace_line in failure.trace: print(f\u0026#34;{trace_line.filename}:{trace_line.lineno} in `{trace_line.function}`\u0026#34;) A saída será algo como:\n/returns/returns/result.py:529 in `Failure` /exemplo_folder/exemplo.py:5 in `retorna_falha` /exemplo_folder/exemplo.py:1 in `\u0026lt;module\u0026gt;` Extra O objetivo principal da feature de rastreamento é dar ao usuário a habilidade de encontrar onde a falha aconteceu, mas se você não quer analizar a pilha de chamadas e sabe o cenário onde a falha ocorre, use o plugin da returns para pytest para verificar sua hipótese. Nós disponibilizamos uma fixture chamada returns com o método has_trace, de uma olhada no exemplo abaixo:\nfrom returns.result import Result, Success, Failure def funcao_exemplo(arg: str) -\u0026gt; Result[int, str]: if arg.isnumeric(): return Success(int(arg)) return Failure(\u0026#39;\u0026#34;{0}\u0026#34; não é um número\u0026#39;.format(arg)) def test_if_failure_is_created_at_exemplo(returns): with returns.has_trace(Failure, funcao_exemplo): Success(\u0026#39;não é número\u0026#39;).bind(funcao_exemplo) Se test_if_failure_is_created_at_exemplo falhar nós sabemos que a falha não foi criada na funcao_exemplo ou em alguma de suas chamadas internas.\nLinks relacionados  Hear no evil, see no evil, patch no evil: Or, how to monkey-patch safely. Monkey Patching and its consequences  ","permalink":"https://thepabloaguilar.dev/pt-br/monkey-patching-nao-e-tao-ruim/","summary":"Contexto Há alguns meses atrás comecei a contribuir em biblioteca Open Source para python, returns, ela têm vários recursos e contêineres legais para nos ajudar de diferentes maneiras. Não irei me aprofundar neles nesse post, mas você pode acessar a documentação para saber mais sobre!\nNesse post irei falar sobre o porquê nós escolhemos a técnica de monkey patching para implementar uma de nossas features onde o objetivo era melhorar a rastreabilidade de falhas para os contêineres Result.","title":"Monkey Patching não é tão ruim"}]